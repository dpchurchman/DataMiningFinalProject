---
title: "Data Mining Lab 3"
author: "Gregroy Asamoah, David Churchman, Ann Nelson"
date: "July 28, 2018"
output:
  html_document:
    theme: journal
    highlight: pygments
    number_sections: true
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(rmarkdown)
library(arules)
library(tidyr)
library(arulesViz)
```

# Business Understanding
<!--[10 points] Describe the purpose of the data set you selected (i.e., why was this data collected in the first place?). How will you measure the effectiveness of a good algorithm? Why does your chosen validation method make sense for this specific dataset and the stakeholders needs?-->

With frequent news of school shootings and police-related violence, there is widespread interest in studying data associated with gun violence incidents. A data set recording all U.S. gun violence events between January 2013 and March 2018, is available for study on [kaggle.com](https://www.kaggle.com/jameslko/gun-violence-data). This data was mined from the Gun Violence Archive using a Python script by James Ko and posted publicly on Kaggle for open investigation. The Gun Violence Archive collects its data by utilizing, "automated queries, manual research through over 2,000 media sources, aggregates, police blotters, police media outlets and other sources daily. Each incident is verified by both initial researchers and secondary validation processes." 

This dataset contains a record of more than 230,000 U.S. gun-related incidents, providing detailed information about the event location both geographic and descriptive, number of participants, number killed or injured, etc. and data related to the shooters and victims (such as age, relationships, count, gender). The dataset also includes a link to the news source from which the data record was obtained. The dataset was created to help close an information-availability gap and make data related to gun violence readily available for analysis, providing opportunity for identifying correlations, developing predictive trend models, and influencing decision-making. 

In the previous two labs, we did exploratory analysis of the data and created algorithms aimed at predicting the level of fatality of a given shooting incident based on the dataset. We used a variety of classification and regression techniques, but in the end, our predictions were only a small amount greater than chance. Though this data set is extensive, it is still limited in quality, and may not provide enough information or reliable enough information to be highly predictive. 

In this lab, rather than attempting predictions, we will look for associations in the dataset, and attempt to create and interpret rules of association which can explain broad trends in gun violence incidents from the last five years. These rules of association could potentially help law enforcement, journalists and researchers better understand patterns found in shooting incidents. 

# Data understanding 1
<!--[10 points] Describe the meaning and type of data (scale, values, etc.) for each attribute in the data file. Verify data quality: Are there missing values? Duplicate data? Outliers? Are those mistakes? How do you deal with these problems?-->

To begin, we downloaded the data as a csv and loaded it into a dataframe. The data includes 29 variables. We focused extensively on the number killed and injured in our predictive models, but will drop these variables for this analysis in order to focus on other categorical measures. Similary, nine variables of have to do with the location of the incident. We did find in previous labs that the state the shooting occurred appeared to have some predictive power, but for the sake of speed and reducing dimensionality, we will drop all location variables. We also saw seasonal and day-of-the-week effects, but in this case, we will drop the date variables. Additionally, we will drop the three variables having to do with links to sources for more information about the shooting, as well as the variable "notes," which are unstructured qualitative descriptions of each incident and the participants names. There is both 'participant_age' and 'age_group', so we will drop the continuous 'age' to use 'age_group'. 

In addition to shooting incidents, the dataset includes a number of gun-seizures from crime scenes and airports that involved large numbers of guns but no victims or shootings, so these incidents were removed from the dataset.

This leaves 9 variables for analysis: 
* incident_id: a unique identifier for each incident.
* gun_stolen: Key-value pairs of whether each gun in the incident was stolen
* gun_type: Key-value pairs, using the same key as 'gun_stolen' describing the type of gun used
* incident_characteristics: a category describing the incident, i.e. "Drive-by", "Armed robbery", etc.
* participants: five variables contain key-value pairs describing the different participants in the incident: 
  + age_group
  + gender
  + relationship, i.e. "family", "significant other", etc.
  + status, i.e. "killed", "unharmed", "arrested", etc.
  + type: "victim" or "suspect"

```{r loadcsv,results='asis'}
#load <- read.csv("gunViolence.csv", header=TRUE)
df <- subset(load, select=-c(incident_url,notes,location_description,participant_name,
                            n_killed, n_injured, n_guns_involved,
                           state_senate_district, sources, state,participant_age, date,
                           longitude,latitude,congressional_district,state_house_district,
                           incident_url_fields_missing,source_url,address,city_or_county))

df <- df[!grepl("Non-Shooting Incident", df$incident_characteristics),]
df <- df[!grepl("Gun buy back action", df$incident_characteristics),]
df <- df[!grepl("Possession \\(gun\\(s\\) found during commission of other crimes\\)", 
                df$incident_characteristics),]

library(knitr)
kable(summary(df[,2:ncol(df)]))
```

The summary table above shows high frequency examples from each of these remaining variables. There are `r dim(df)[1]` total incidents left after cleaning. Of the variables left for analysis, the most complete is "incident_characteristics." The key-value pairs describing guns and the participants are all missing tens of thousands of values, which made them problematic when we were creating prediction models, however association rules are designed around very sparse datasets like market-basket analysis, so it should be robust to these missing values. The structure of the key-value pairs will require further formatting before analysis can be completed. 

# Data understanding 2
<!-- [10 points]  Visualize the any important attributes appropriately. Important: Provide an interpretation for any charts or graphs.-->

One key feature of the data is "incident_characteristics", which contains categorical descriptors. Because of the large number of unique descriptors, we did not include this variable in previous labs, but using the tools of creating association rules gives several ways to help give better insight into this variable, which is essentially a short summary of each incident. First, we can transform the incidents into transactional data format and look at a brief summary: 

```{r IncidentRules}
# Create dfInc for initial Association Rules analysis on just "Incident Characterics"
dfInc <-  df[c('incident_id','incident_characteristics')]

# Reshape dfInc into long format using tidyr in order to get it into transaction format for arules

dfIncLong <- dfInc %>%  # Since the separator || is an operator, need \\ as escape
  separate_rows(incident_characteristics, sep="\\|\\|") 

# Change into transaction data for arules

transInc <- as(split(dfIncLong[,'incident_characteristics'],dfIncLong[,'incident_id']),
               "transactions")
#inspect(head(transInc))
summary(transInc)
```

We can see the most frequent items are ones that describe that people were shot, and whether they were wounded, unharmed or killled. Also high in frequency are armed robberies and officer-involved incidents. Most incidents have one or two descriptors, but there are incidents with as many eight descriptors. We can see these, as well as many of the less frequent descriptors in the following item frequency plot, which shows the large number of situations described like car-jackings or gang-involvement.


```{r incidentFrequencyPlot, echo=FALSE}
# Plot to see most frequent items
itemFrequencyPlot(transInc, support=0.01, cex.names=.5)
```

There are 504 total descriptors, so what might give better insight into this dataset is which tend to appear together in incidents, which may also reveal redundant descriptors. To get a broad array of rules, we will set the minimum support and confidence relatively low at 0.01 and 0.1 respectively.

```{r incidentrules}
rulesInc <- apriori(transInc, parameter = list(support=0.01, confidence=.1))
```

We can see 92 rules were created comparing the descriptors in incidents. Of note is the relative speed of creating these association rules. Over 180,000 incidents with 504 different descriptors were compared in less than a second on a commercially available laptop. Next, we will look at the top ten rules by confidence.

```{r 10tenincidentrules}
inspect(head(rulesInc, n=10), by="confidence")
```

The top three are not surprising, as they were the single descriptors with the highest frequency by far in the frequency plot above. Rules 4-6 all have to do with home-invasion. It seems that when most incidents are labeled as a "home invasion" in the dataset, there is an additional classifier describing the type of home invasion. The next two rules show something similar with Murder/Suicides, and the last two about Officer involved shootings. To visualize these groupings of rules around descriptors that tend to appear together for incidents, we will create a graph plot on all 92 rules. 

```{r RuleGraph, echo=FALSE}
plot(head(rulesInc,n=30, by="lift"), method="graph")
```

In addition to the home invasion, murder suicide and officer involved shooting groups we saw in the top 10 rules, we can see descriptors around accidental shootings and defensive shootings as well. These five main clusters all most likely have very different attributes, and in future regression and classification, they could be disaggregated and explored individually. 

# Modeling and Evaluation 1
<!-- [10 points] 	Train and adjust parameters -->



# Modeling and Evaluation 2
<!-- [10 points] Evaluate and Compare -->

# Modeling and Evaluation 3
<!-- [10 points] Visualize Results -->

# Modeling and Evaluation 4
<!-- [20 points] Summarize the ramifications -->

# Deployment 
<!-- [10 points] Be critical of your performance and tell the reader how you current model might be usable by other parties. Did you achieve your goals? If not, can you reign in the utility of your modeling? How useful is your model for interested parties (i.e., the companies or organizations that might want to use it)? How would your deploy your model for interested parties? What other data should be collected? How often would the model need to be updated, etc.? -->

# Exceptional Work
<!-- [10 points] You have free reign to provide additional analyses or combine analyses. -->








